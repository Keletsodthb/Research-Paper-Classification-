{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test KNN model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the test data and predict the research field for randomly chosen reseach papers. This will enable us to see how the model works on new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to import:\n",
    "\n",
    "* Trained models\n",
    "* TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import punkt\n",
    "from nltk.corpus.reader import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pd.set_option('display.max_colwidth', -1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = \"C:/Users/Keletso/Documents/Research Paper Classification/3. Model Training/Models/\"\n",
    "\n",
    "# SVM\n",
    "path_knnc = path_models + 'best_knnc.pickle'\n",
    "with open(path_knnc, 'rb') as data:\n",
    "    knnc_model = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tfidf = \"C:/Users/Keletso/Documents/Research Paper Classification/2. Feature Engineering/Pickles/tfidf.pickle\"\n",
    "with open(path_tfidf, 'rb') as data:\n",
    "    tfidf = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research paper mapping dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Research_Field_codes = {\n",
    "    'Computer Science': 0,\n",
    "    'Physics': 1,\n",
    "    'Mathematics': 2,\n",
    "    'Statistics': 3,\n",
    "    'Quantitative Biology': 4,\n",
    "    'Quantitative Finance': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\")\n",
    "stop_words = list(stopwords.words('english'))\n",
    "def clean_text(df_test): \n",
    "    df=df_test.copy()\n",
    "    df['Title_Parsed_1'] = df['TITLE'].str.replace(\"\\n\", \" \")\n",
    "    df['Title_Parsed_1'] = df['Title_Parsed_1'].str.replace(\"$\", \" \")\n",
    "    df['Title_Parsed_1'] = df['Title_Parsed_1'].str.replace(\"\\\\\", \" \")\n",
    "    df['Title_Parsed_1'] = df['Title_Parsed_1'].str.replace(\"\\`\", \" \")                                                                    \n",
    "    df['ABSTRACT_Parsed_1'] = df['ABSTRACT'].str.replace(\"\\n\", \" \")\n",
    "    df['ABSTRACT_Parsed_1'] = df['ABSTRACT_Parsed_1'].str.replace(\"$\", \" \")\n",
    "    df['ABSTRACT_Parsed_1'] = df['ABSTRACT_Parsed_1'].str.replace(\"\\\\\", \" \")\n",
    "    df['ABSTRACT_Parsed_1'] = df['ABSTRACT_Parsed_1'].str.replace(\"\\`\", \" \")\n",
    "    df['Title_Parsed_2'] = df['Title_Parsed_1'].str.lower()\n",
    "    df['ABSTRACT_Parsed_2'] = df['ABSTRACT_Parsed_1'].str.lower()\n",
    "    df['Title_Parsed_3'] = df['Title_Parsed_2']\n",
    "    df['ABSTRACT_Parsed_3'] = df['ABSTRACT_Parsed_2']\n",
    "    for punct_sign in punctuation_signs:\n",
    "        df['Title_Parsed_3'] = df['Title_Parsed_3'].str.replace(punct_sign, '')\n",
    "        df['ABSTRACT_Parsed_3'] = df['ABSTRACT_Parsed_3'].str.replace(punct_sign, '')\n",
    "    df['Title_Parsed_4'] = df['Title_Parsed_3'].str.replace(\"'s\", \"\")\n",
    "    df['ABSTRACT_Parsed_4'] = df['ABSTRACT_Parsed_3'].str.replace(\"'s\", \"\")\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    nrows = len(df)\n",
    "    lemmatized_title_list = []\n",
    "    lemmatized_abstract_list = []\n",
    "        # Create an empty list containing lemmatized words\n",
    "    title_list = []\n",
    "    abstract_list = []\n",
    "\n",
    "    # Save the text and its words into an object\n",
    "    title = df['Title_Parsed_4'].to_string(index=False)\n",
    "    title_words = title.split(\" \")\n",
    "\n",
    "    abstract = df['ABSTRACT_Parsed_4'].to_string(index=False)\n",
    "    abstract_words = abstract.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in title_words:\n",
    "        title_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "\n",
    "    for word in abstract_words:\n",
    "        abstract_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "    # Join the list\n",
    "    lemmatized_title = \" \".join(title_list)\n",
    "    lemmatized_abstract = \" \".join(abstract_list)\n",
    "\n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_title_list.append(lemmatized_title)\n",
    "    lemmatized_abstract_list.append(lemmatized_abstract)\n",
    "    df['Title_Parsed_5'] = lemmatized_title_list\n",
    "    df['ABSTRACT_Parsed_5'] = lemmatized_abstract_list\n",
    "    df['Title_Parsed_6'] = df['Title_Parsed_5']\n",
    "    df['ABSTRACT_Parsed_6'] = df['ABSTRACT_Parsed_5']\n",
    "    for stop_word in stop_words:\n",
    "\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        df['Title_Parsed_6'] = df['Title_Parsed_6'].str.replace(regex_stopword, '')\n",
    "        df['ABSTRACT_Parsed_6'] = df['ABSTRACT_Parsed_6'].str.replace(regex_stopword, '')\n",
    "    list_columns = [\"Title_Parsed_6\", \"ABSTRACT_Parsed_6\"]\n",
    "    df = df[list_columns]\n",
    "\n",
    "    df = df.rename(columns={'Title_Parsed_6': 'Title_Parsed','ABSTRACT_Parsed_6': 'ABSTRACT_Parsed'})\n",
    "    df['Article_Description']=df['Title_Parsed'] + df['ABSTRACT_Parsed']\n",
    "\n",
    "    df_final=df['Article_Description']\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function that tells us the research field given the category code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fields(field_id): \n",
    "    for field, id_  in Research_Field_codes.items():\n",
    "        if id_ == field_id:      \n",
    "            return field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here's the function that will predict the research field given a title and description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_text(text):\n",
    "    \n",
    "    # Predict using the input model\n",
    "    features = tfidf.transform([text]).toarray()\n",
    "    prediction_knnc = knnc_model.predict(features)[0]\n",
    "    \n",
    "    # Return result\n",
    "    field_knnc = get_fields(prediction_knnc)\n",
    "    \n",
    "    print(\"The predicted category using the knn model is %s.\" %(field_knnc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get unseen data from the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('C:/Users/Keletso/Documents/Research Paper Classification/0. Raw Data Set/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  macroscopic irreversibility  decay  kinetic equilibrium  classical hard-sphere systems     paper  condition  investigate   occurrence   -called macroscopic irreversibility property   relate phenomenon  decay  kinetic equilibrium  may characterize   1- body probability density function (pdf) associate  hard-sphere systems  problem  set   framework   axiomatic \"ab initio\" approach  classical statistical mechanics recently develop [tessarotto  textit{et al} 2013-2017]   relate establishment   exact kinetic equation realize  master equation    kinetic pdf  show   paper  task involve  introduction   suitable functional    1- body pdf  identify    textit{master kinetic information}  goal   show  provide   pdf  realize  term   arbitrary suitably-smooth particular solution   master kinetic equation  two properties indicate   indeed realize     functional  unrelated either   boltzmann-shannon entropy   fisher information '"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test=df_test.sample(1)\n",
    "sample_cleaned_text=clean_text(sample_test).to_string(index=False)\n",
    "sample_cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted category using the knn model is Physics.\n"
     ]
    }
   ],
   "source": [
    "predict_from_text(sample_cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  concordances  connect sum  torus knot  l-space knot     knot   nontrivial connect sum  positive torus knot     concordant   l-space knot '"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test=df_test.sample(1)\n",
    "sample_cleaned_text=clean_text(sample_test).to_string(index=False)\n",
    "sample_cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted category using the knn model is Mathematics.\n"
     ]
    }
   ],
   "source": [
    "predict_from_text(sample_cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  rational neural network  approximate jump discontinuities  graph convolution operator    node level graph encode  recent important state--art method   graph convolutional network (gcn)  nicely integrate local vertex feature  graph topology   spectral domain however current study suffer  several drawbacks (1) graph cnns rely  chebyshev polynomial approximation  result  oscillatory approximation  jump discontinuities (2) increase  order  chebyshev polynomial  reduce  oscillations issue  also incur unaffordable computational cost (3) chebyshev polynomials require degree   omega (poly(1/  epsilon ))  approximate  jump signal    |x|   rational function  need   mathcal{} (poly log(1/  epsilon )) cite{liang2016deeptelgarsky2017neural} however  non-trivial  apply rational approximation without increase computational complexity due   denominator   paper  superiority  rational approximation  exploit  graph signal recover ratioanlnet  propose  integrate rational function  neural network  show  rational function  eigenvalues   rewrite   function  graph laplacian   avoid multiplication   eigenvector matrix focus   analysis  approximation  graph convolution operation  graph signal regression task  formulate  graph signal regression task  time complexity   significantly reduce  graph fourier transform  overcome  local minimum problem  neural network model  relax remez algorithm  utilize  initialize  weight parameters convergence rate  ratioanlnet  polynomial base methods  jump signal  analyze   theoretical guarantee  extensive experimental result demonstrate   approach could effectively characterize  jump discontinuities outperform compete methods   substantial margin   synthetic  real-world graph '"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test=df_test.sample(1)\n",
    "sample_cleaned_text=clean_text(sample_test).to_string(index=False)\n",
    "sample_cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted category using the knn model is Computer Science.\n"
     ]
    }
   ],
   "source": [
    "predict_from_text(sample_cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
